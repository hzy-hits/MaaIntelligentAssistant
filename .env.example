# MAA 智能服务器配置示例
# 复制此文件为 .env 并填入实际配置

# =============================================================================
# AI 配置 - 基于 async-openai 的多提供商支持
# =============================================================================

# 默认 AI 提供商 (openai, azure, qwen, kimi, ollama)
AI_PROVIDER=qwen

# 默认提供商配置
AI_API_KEY=your-default-api-key
AI_MODEL=qwen-turbo
AI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=4096
AI_TIMEOUT=60

# OpenAI 配置
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4
# OPENAI_BASE_URL=  # 使用默认 URL

# Azure OpenAI 配置
AZURE_API_KEY=your-azure-api-key
AZURE_BASE_URL=https://your-resource.openai.azure.com
AZURE_MODEL=gpt-4  # 这里是部署名称，不是模型名称

# 阿里云通义千问配置
QWEN_API_KEY=your-qwen-api-key
QWEN_MODEL=qwen-turbo
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# 月之暗面 Kimi 配置
KIMI_API_KEY=your-kimi-api-key
KIMI_MODEL=moonshot-v1-8k
KIMI_BASE_URL=https://api.moonshot.cn/v1

# Ollama 本地部署配置
OLLAMA_MODEL=llama2
OLLAMA_BASE_URL=http://localhost:11434/v1
# OLLAMA_API_KEY=  # 本地部署通常不需要 API Key

# =============================================================================
# 兼容性配置 - 旧版本配置格式，新版本会自动使用上面的新格式
# =============================================================================
# AI_API_KEY=your-api-key
# AI_API_ENDPOINT=https://dashscope.aliyuncs.com/compatible-mode/v1
# AI_MODEL=qwen-turbo

# =============================================================================
# MAA 配置
# =============================================================================
MAA_DEVICE=127.0.0.1:5555
MAA_ADB_PATH=adb
MAA_RESOURCE_PATH=./maa-official/resource

# =============================================================================
# 服务器配置
# =============================================================================
SERVER_HOST=0.0.0.0
SERVER_PORT=8080
LOG_LEVEL=info

# =============================================================================
# 缓存配置
# =============================================================================
CACHE_DIR=./data
CACHE_TTL=3600

# =============================================================================
# 作业站配置
# =============================================================================
COPILOT_API_URL=https://prts.maa.plus
COPILOT_CACHE_TTL=1800

# =============================================================================
# 使用说明
# =============================================================================
# 1. 至少需要配置一个 AI 提供商的 API Key
# 2. 推荐配置多个提供商作为备选
# 3. Ollama 用于本地部署，不需要 API Key
# 4. Azure 需要同时配置 API Key 和 Base URL
# 5. 各提供商的 Model 参数说明：
#    - OpenAI: gpt-3.5-turbo, gpt-4, gpt-4-turbo 等
#    - Azure: 使用部署名称，不是模型名称
#    - Qwen: qwen-turbo, qwen-plus, qwen-max 等
#    - Kimi: moonshot-v1-8k, moonshot-v1-32k, moonshot-v1-128k
#    - Ollama: 本地安装的模型名称，如 llama2, codellama 等